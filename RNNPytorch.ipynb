{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('kafka.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.split()\n",
    "data = data[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vocab = {x:i for i,x in enumerate(set(data))}\n",
    "index_vocab = {v:k for k,v in char_vocab.items()}\n",
    "data_index = [char_vocab[x] for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(data_index)\n",
    "labels = data_index[1:]\n",
    "labels.append(data_index[0])\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len = 5\n",
    "input_size = 10\n",
    "num_layers = 1\n",
    "hidden_size = 1024\n",
    "batch_size = 20\n",
    "num_classes = len(char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.view(batch_size, -1)\n",
    "labels = labels.view(batch_size, -1)\n",
    "num_batches = inputs.size(1) // sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNToy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNToy, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(char_vocab), 10)\n",
    "        self.cell = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        emb = self.embedding(x)\n",
    "        out, _ = self.cell(emb, h)\n",
    "        out = self.linear(out.reshape(-1, hidden_size))\n",
    "        return out\n",
    "\n",
    "def detach(states):\n",
    "    return [state.detach() for state in states] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNToy().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001/2*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoh : 1/45] loss=7.02563604927063\n",
      "[Epoh : 2/45] loss=6.242861427307129\n",
      "[Epoh : 3/45] loss=5.77207360458374\n",
      "[Epoh : 4/45] loss=5.239101715087891\n",
      "[Epoh : 5/45] loss=4.594894106864929\n",
      "[Epoh : 6/45] loss=3.9215585660934447\n",
      "[Epoh : 7/45] loss=3.3588982458114622\n",
      "[Epoh : 8/45] loss=2.952076895713806\n",
      "[Epoh : 9/45] loss=2.6245068140029906\n",
      "[Epoh : 10/45] loss=2.3117921476364134\n",
      "[Epoh : 11/45] loss=2.0391876759529115\n",
      "[Epoh : 12/45] loss=1.8614677233695984\n",
      "[Epoh : 13/45] loss=1.7154134640693663\n",
      "[Epoh : 14/45] loss=1.591266420841217\n",
      "[Epoh : 15/45] loss=1.485338463306427\n",
      "[Epoh : 16/45] loss=1.3864935803413392\n",
      "[Epoh : 17/45] loss=1.302882091999054\n",
      "[Epoh : 18/45] loss=1.2280837464332581\n",
      "[Epoh : 19/45] loss=1.1650268371105195\n",
      "[Epoh : 20/45] loss=1.1125070986747743\n",
      "[Epoh : 21/45] loss=1.0726917366981505\n",
      "[Epoh : 22/45] loss=1.0447366874217987\n",
      "[Epoh : 23/45] loss=1.017480136871338\n",
      "[Epoh : 24/45] loss=0.9974478094577789\n",
      "[Epoh : 25/45] loss=0.9765981900691986\n",
      "[Epoh : 26/45] loss=0.9599587173461914\n",
      "[Epoh : 27/45] loss=0.9426541810035706\n",
      "[Epoh : 28/45] loss=0.9317875247001648\n",
      "[Epoh : 29/45] loss=0.9216535396575928\n",
      "[Epoh : 30/45] loss=0.8996229183673858\n",
      "[Epoh : 31/45] loss=0.8794791667461396\n",
      "[Epoh : 32/45] loss=0.8578267593383789\n",
      "[Epoh : 33/45] loss=0.8403813166618347\n",
      "[Epoh : 34/45] loss=0.823610595703125\n",
      "[Epoh : 35/45] loss=0.8133738181591034\n",
      "[Epoh : 36/45] loss=0.8029638893604278\n",
      "[Epoh : 37/45] loss=0.7939597647190094\n",
      "[Epoh : 38/45] loss=0.7835185391902924\n",
      "[Epoh : 39/45] loss=0.7745318223237991\n",
      "[Epoh : 40/45] loss=0.7660211449861527\n",
      "[Epoh : 41/45] loss=0.7595734430551528\n",
      "[Epoh : 42/45] loss=0.7516199003458023\n",
      "[Epoh : 43/45] loss=0.7462879300117493\n",
      "[Epoh : 44/45] loss=0.7398116742372512\n",
      "[Epoh : 45/45] loss=0.7333016146421433\n"
     ]
    }
   ],
   "source": [
    "num_of_epoh = 45\n",
    "for epoh in range(num_of_epoh):\n",
    "    states = (torch.zeros(num_layers, batch_size, hidden_size).to(device),\n",
    "                 torch.zeros(num_layers, batch_size, hidden_size).to(device))\n",
    "    avg_loss = 0\n",
    "    for i in range(0, inputs.size(1)-sequence_len, sequence_len):\n",
    "        batch_in = inputs[:, i: i+sequence_len].to(device)\n",
    "        batch_label = labels[:, i: i+sequence_len].to(device)\n",
    "        states = detach(states)\n",
    "        output = model(batch_in, states)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, batch_label.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item()\n",
    "        step = (i+1) // sequence_len\n",
    "    print(\"[Epoh : {}/{}] loss={}\".format(epoh+1, num_of_epoh, avg_loss/num_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNToy(\n",
       "  (embedding): Embedding(4565, 10)\n",
       "  (cell): LSTM(10, 1024, batch_first=True)\n",
       "  (linear): Linear(in_features=1024, out_features=4565, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('model.ckpt', map_location=device))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to Model: One\n",
      "\n",
      "Expected Output:\n",
      "One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin. He lay on his armour-like back, and if he lifted his head a little he could see his brown belly, slightly domed and divided by arches into stiff sections. The\n",
      "\n",
      "Predicted Output after Sampling:\n",
      "One floor; shock defend breadth dressed, 1.E.6. electronically PURPOSE. below. charge dressed, equipment. building old renamed. mistrust going insistent butcher's barricade consisting explaining crawling going consisting inedible fog convulsive thus below. sharply must below. permitted dressed, stuck dressed, \"get shame, straight seen\", before? going explaining search shock explaining hugged mistrust I've\n",
      "\n",
      "Predicted Output without Sampling:\n",
      "One floor; us explaining breadth dressed, explaining electronically dressed, came, Any dressed, explaining building old hostile, mistrust morning explaining slumber barricade months, itself crawling us explaining itself directions. unhappy conversation below. Any must old Any dressed, explaining leapt explaining food straight explaining consisting vermin. explaining crawling Any explaining crawling us morning\n"
     ]
    }
   ],
   "source": [
    "output = None\n",
    "predected_sent_index = data_index[:1]\n",
    "predected_sent_index_2 = data_index[:1]\n",
    "print(\"Input to Model: {}\".format(' '.join(data[:1])))\n",
    "print(\"\\nExpected Output:\\n{}\".format(' '.join(data[:50])))\n",
    "with torch.no_grad():\n",
    "    states = (torch.zeros(num_layers, 1, hidden_size).to(device),\n",
    "            torch.zeros(num_layers, 1, hidden_size).to(device))\n",
    "    prob = torch.ones(len(char_vocab))\n",
    "    input = torch.tensor(char_vocab[\"One\"]).reshape(1,1).to(device)\n",
    "    for i in range(50):\n",
    "        # Forward propagate RNN \n",
    "        output = model(input, states)\n",
    "        prob = output.exp()\n",
    "        word_id = torch.multinomial(prob, num_samples=1).item()\n",
    "        input.fill_(word_id)\n",
    "        predected_sent_index.append(word_id)\n",
    "        predected_sent_index_2.extend(torch.max(output, 1)[1].tolist())\n",
    "print(\"\\nPredicted Output after Sampling:\\n{}\".format(' '.join([index_vocab[x] for x in predected_sent_index])))\n",
    "print(\"\\nPredicted Output without Sampling:\\n{}\".format(' '.join([index_vocab[x] for x in predected_sent_index_2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
